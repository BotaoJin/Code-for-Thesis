{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOeur3ROqtYfA/TMIAthucq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BotaoJin/Code-for-Thesis/blob/main/AD_EnKF_nonlinear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv2Q1gYq_Zao",
        "outputId": "33cb9f21-5610-460c-de94-fe212a6695fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from torchdiffeq) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->torchdiffeq) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torchdiffeq\n",
        "from torchdiffeq import odeint\n",
        "from torchdiffeq import odeint_adjoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Lorenz63(nn.Module):\n",
        "  def __init__(self, sigma, beta, rho, x_dim = 3):\n",
        "      super().__init__()\n",
        "      self.sigma = nn.Parameter(sigma)\n",
        "      self.beta = nn.Parameter(beta)\n",
        "      self.rho = nn.Parameter(rho)\n",
        "      self.x_dim = 3\n",
        "\n",
        "  def forward(self, t, u):\n",
        "    sigma = self.sigma\n",
        "    beta = self.beta\n",
        "    rho = self.rho\n",
        "    out = torch.stack((sigma*(u[...,1]-u[...,0]), rho*u[..., 0]-u[..., 0]*u[..., 2]-u[..., 1], u[..., 0]*u[..., 1]-beta*u[..., 2]), dim = -1)\n",
        "    return out"
      ],
      "metadata": {
        "id": "NYK1Sr39_r9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dim = 3\n",
        "y_dim = 3\n",
        "H = torch.eye(3)\n",
        "cov = torch.eye(3)\n",
        "gamma = .1\n",
        "T_ = 100\n",
        "t1 = torch.tensor([0., .01])\n",
        "\n",
        "def generate_data(ode_func):\n",
        "  x0 = torch.tensor([1., 1., 1.])\n",
        "  X = torch.empty(T_+1, x_dim)\n",
        "  Y = torch.empty(T_, y_dim)\n",
        "  X[0] = x0\n",
        "\n",
        "  for t in range(T_):\n",
        "    X[t+1] = odeint(ode_func, X[t], t1)[-1]\n",
        "    X[t+1] = MultivariateNormal(X[t+1], gamma**2*cov).sample()\n",
        "    Y[t] = MultivariateNormal(X[t+1], gamma**2*cov).sample()\n",
        "\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "RfWvINLK_u_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate data\n",
        "true_sigma = torch.tensor(10.0)\n",
        "true_beta = torch.tensor(8.0/3.0)\n",
        "true_rho = torch.tensor(28.0)\n",
        "\n",
        "true_ode_func = Lorenz63(sigma = true_sigma, beta = true_beta, rho = true_rho)\n",
        "X, Y = generate_data(true_ode_func)"
      ],
      "metadata": {
        "id": "kT7bQGzs_ycl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EnKF(ode_func, Y, N_ensem, t_span, x0 = torch.tensor([1., 1., 1.])):\n",
        "  T = Y.shape[-2]\n",
        "  X = x0.expand((N_ensem, x_dim))\n",
        "  res = torch.empty(T+1, N_ensem, x_dim)\n",
        "  res[0] = X\n",
        "  mean = torch.zeros(x_dim)\n",
        "  log_likelihood = torch.tensor(0.)\n",
        "\n",
        "  for t in range(T):\n",
        "    # Forcast Step\n",
        "    X = odeint_adjoint(ode_func, X, t_span, method = 'rk4', adjoint_method = 'rk4')[-1]\n",
        "    X = X + MultivariateNormal(mean.expand((N_ensem, x_dim)), (gamma**2)*cov).sample() # model error for X: dim = (N_ensem, x_dim)\n",
        "    X_m = X.mean(dim = -2).unsqueeze(-2) # dim = (1, x_dim)\n",
        "    X_ct = X - X_m\n",
        "\n",
        "    # Analysis Step\n",
        "    y_obs_j = Y[t].unsqueeze(-2) # dim = (1, y_dim)\n",
        "    y_obs_perturb = MultivariateNormal(y_obs_j.expand(N_ensem, y_dim), (gamma**2)*cov).sample()\n",
        "\n",
        "    C_uu = 1/(N_ensem - 1)*X_ct.transpose(-1, -2)@X_ct # dim = (1, x_dim)\n",
        "    # In this model, setting H = I\n",
        "    HX = X\n",
        "    HX_m = X_m\n",
        "    HC = C_uu\n",
        "    HCH_T = HC\n",
        "    HCH_TR_chol = torch.linalg.cholesky(HCH_T + (gamma**2)*cov)\n",
        "    d = MultivariateNormal(HX_m.squeeze(-2), scale_tril = HCH_TR_chol)\n",
        "    log_likelihood += d.log_prob(y_obs_j.squeeze(-2))\n",
        "\n",
        "    # Update and store X_j^{1:N}\n",
        "    pre = (y_obs_perturb-HX)@torch.cholesky_inverse(HCH_TR_chol)\n",
        "    X = X + pre@HC\n",
        "    res[t+1] = X\n",
        "\n",
        "  return X, res, log_likelihood"
      ],
      "metadata": {
        "id": "aK4nAGeT_3bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (sigma unknown, N = 10)\n",
        "sigma, beta, rho = torch.tensor(.01), true_beta, true_rho\n",
        "iter_sigma_GD = [sigma]\n",
        "iter_grad_sigma = []\n",
        "eta_sigma = 1e-3\n",
        "\n",
        "for j in range(200):\n",
        "  sigma1 = sigma.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma1, beta, rho)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 10, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_sigma = ode_func.sigma.grad\n",
        "  sigma = sigma + eta_sigma*grad_sigma\n",
        "\n",
        "  iter_sigma_GD.append(sigma)\n",
        "  iter_grad_sigma.append(grad_sigma)"
      ],
      "metadata": {
        "id": "-ouNKpPl_7I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (sigma unknown, N = 100)\n",
        "sigma, beta, rho = torch.tensor(.01), true_beta, true_rho\n",
        "iter_sigma_GD1 = [sigma]\n",
        "iter_grad_sigma1 = []\n",
        "eta_sigma = 1e-3\n",
        "\n",
        "for j in range(200):\n",
        "  sigma1 = sigma.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma1, beta, rho)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 100, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_sigma = ode_func.sigma.grad\n",
        "  sigma = sigma + eta_sigma*grad_sigma\n",
        "\n",
        "  iter_sigma_GD1.append(sigma)\n",
        "  iter_grad_sigma1.append(grad_sigma)"
      ],
      "metadata": {
        "id": "p9v60b-A-odH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (sigma unknown, N = 1000)\n",
        "sigma, beta, rho = torch.tensor(.01), true_beta, true_rho\n",
        "iter_sigma_GD2 = [sigma]\n",
        "iter_grad_sigma2 = []\n",
        "eta_sigma = 1e-3\n",
        "\n",
        "for j in range(200):\n",
        "  sigma1 = sigma.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma1, beta, rho)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 1000, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_sigma = ode_func.sigma.grad\n",
        "  sigma = sigma + eta_sigma*grad_sigma\n",
        "\n",
        "  iter_sigma_GD2.append(sigma)\n",
        "  iter_grad_sigma2.append(grad_sigma)"
      ],
      "metadata": {
        "id": "f_ni4x7ImIXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (beta unknown, N = 10)\n",
        "sigma, beta, rho = true_sigma, torch.tensor(0.), true_rho\n",
        "iter_beta_GD = [beta]\n",
        "iter_grad_beta = []\n",
        "eta_beta = 1e-4\n",
        "\n",
        "for j in range(200):\n",
        "  beta1 = beta.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma, beta1, rho)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 10, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_beta = ode_func.beta.grad\n",
        "  beta = beta + eta_beta*grad_beta\n",
        "\n",
        "  iter_beta_GD.append(beta)\n",
        "  iter_grad_beta.append(grad_beta)"
      ],
      "metadata": {
        "id": "K3VbNTFnAU_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (beta unknown, N = 100)\n",
        "sigma, beta, rho = true_sigma, torch.tensor(0.), true_rho\n",
        "iter_beta_GD1 = [beta]\n",
        "iter_grad_beta1 = []\n",
        "eta_beta = 1e-4\n",
        "\n",
        "for j in range(200):\n",
        "  beta1 = beta.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma, beta1, rho)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 100, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_beta = ode_func.beta.grad\n",
        "  beta = beta + eta_beta*grad_beta\n",
        "\n",
        "  iter_beta_GD1.append(beta)\n",
        "  iter_grad_beta1.append(grad_beta)"
      ],
      "metadata": {
        "id": "0fF18kir--EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (beta unknown, N = 1000)\n",
        "sigma, beta, rho = true_sigma, torch.tensor(0.), true_rho\n",
        "iter_beta_GD2 = [beta]\n",
        "iter_grad_beta2 = []\n",
        "eta_beta = 1e-4\n",
        "\n",
        "for j in range(200):\n",
        "  beta1 = beta.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma, beta1, rho)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 1000, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_beta = ode_func.beta.grad\n",
        "  beta = beta + eta_beta*grad_beta\n",
        "\n",
        "  iter_beta_GD2.append(beta)\n",
        "  iter_grad_beta2.append(grad_beta)"
      ],
      "metadata": {
        "id": "CGEN6P2Enyzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (rho unknown, N = 10)\n",
        "sigma, beta, rho = true_sigma, true_beta, torch.tensor(0.)\n",
        "iter_rho_GD = [rho]\n",
        "iter_grad_rho = []\n",
        "eta_rho = 1e-3\n",
        "\n",
        "for j in range(200):\n",
        "  rho1 = rho.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma, beta, rho1)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 10, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_rho = ode_func.rho.grad\n",
        "  rho = rho + eta_rho*grad_rho\n",
        "\n",
        "  iter_rho_GD.append(rho)\n",
        "  iter_grad_rho.append(grad_rho)"
      ],
      "metadata": {
        "id": "EYRMysEqAXRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (rho unknown, N = 100)\n",
        "sigma, beta, rho = true_sigma, true_beta, torch.tensor(0.)\n",
        "iter_rho_GD1 = [rho]\n",
        "iter_grad_rho1 = []\n",
        "eta_rho = 1e-3\n",
        "\n",
        "for j in range(200):\n",
        "  rho1 = rho.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma, beta, rho1)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 100, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_rho = ode_func.rho.grad\n",
        "  rho = rho + eta_rho*grad_rho\n",
        "\n",
        "  iter_rho_GD1.append(rho)\n",
        "  iter_grad_rho1.append(grad_rho)"
      ],
      "metadata": {
        "id": "Eax6OCbM_J29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient ascent (rho unknown, N = 1000)\n",
        "sigma, beta, rho = true_sigma, true_beta, torch.tensor(0.)\n",
        "iter_rho_GD2 = [rho]\n",
        "iter_grad_rho2 = []\n",
        "eta_rho = 1e-3\n",
        "\n",
        "for j in range(200):\n",
        "  rho1 = rho.clone().detach().requires_grad_(True)\n",
        "\n",
        "  ode_func = Lorenz63(sigma, beta, rho1)\n",
        "  x_bar, res, loglike = EnKF(ode_func, Y, N_ensem = 1000, t_span = t1)\n",
        "  loglike.backward()\n",
        "  grad_rho = ode_func.rho.grad\n",
        "  rho = rho + eta_rho*grad_rho\n",
        "\n",
        "  iter_rho_GD2.append(rho)\n",
        "  iter_grad_rho2.append(grad_rho)"
      ],
      "metadata": {
        "id": "1pNq8EuQolEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(18, 4.5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(range(len(iter_sigma_GD)), torch.tensor(iter_sigma_GD).detach().clone(), label = 'N = 10')\n",
        "plt.plot(range(len(iter_sigma_GD1)), torch.tensor(iter_sigma_GD1).detach().clone(), label = 'N = 100')\n",
        "plt.plot(range(len(iter_sigma_GD2)), torch.tensor(iter_sigma_GD2).detach().clone(), label = 'N = 1000')\n",
        "plt.plot(range(len(iter_sigma_GD)), true_sigma * np.ones((len(iter_sigma_GD),)), label = 'True sigma')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('values')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(range(len(iter_beta_GD)), torch.tensor(iter_beta_GD).detach().clone(), label = 'N = 10')\n",
        "plt.plot(range(len(iter_beta_GD1)), torch.tensor(iter_beta_GD1).detach().clone(), label = 'N= 100')\n",
        "plt.plot(range(len(iter_beta_GD2)), torch.tensor(iter_beta_GD2).detach().clone(), label = 'N= 1000')\n",
        "plt.plot(range(len(iter_beta_GD)), true_beta * np.ones((len(iter_beta_GD),)), label = 'True beta')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('values')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(range(len(iter_rho_GD)), torch.tensor(iter_rho_GD).detach().clone(), label = 'N = 10')\n",
        "plt.plot(range(len(iter_rho_GD1)), torch.tensor(iter_rho_GD1).detach().clone(), label = 'N = 100')\n",
        "plt.plot(range(len(iter_rho_GD2)), torch.tensor(iter_rho_GD2).detach().clone(), label = 'N = 1000')\n",
        "plt.plot(range(len(iter_rho_GD)), true_rho * np.ones((len(iter_rho_GD),)), label = 'True rho')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('values')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QoKWRP3nBwx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(18, 4.5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(range(len(iter_grad_sigma)), torch.tensor(iter_grad_sigma).detach().clone(), label = 'grad of sigma with N = 10')\n",
        "plt.plot(range(len(iter_grad_sigma1)), torch.tensor(iter_grad_sigma1).detach().clone(), label = 'grad of sigma with N = 100')\n",
        "plt.plot(range(len(iter_grad_sigma2)), torch.tensor(iter_grad_sigma2).detach().clone(), label = 'grad of sigma with N = 1000')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('grad log-likelihood')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(range(len(iter_grad_beta)), torch.tensor(iter_grad_beta).detach().clone(), label = 'grad of beta with N = 10')\n",
        "plt.plot(range(len(iter_grad_beta1)), torch.tensor(iter_grad_beta1).detach().clone(), label = 'grad of beta with N = 100')\n",
        "plt.plot(range(len(iter_grad_beta2)), torch.tensor(iter_grad_beta2).detach().clone(), label = 'grad of beta with N = 1000')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('grad log-likelihood')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(range(len(iter_grad_rho)), torch.tensor(iter_grad_rho).detach().clone(), label = 'grad of rho with N = 10')\n",
        "plt.plot(range(len(iter_grad_rho1)), torch.tensor(iter_grad_rho1).detach().clone(), label = 'grad of rho with N = 100')\n",
        "plt.plot(range(len(iter_grad_rho2)), torch.tensor(iter_grad_rho2).detach().clone(), label = 'grad of rho with N = 1000')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('grad log-likelihood')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XYAhC-UhFasU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}